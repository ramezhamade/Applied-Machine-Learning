{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab78cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this notebook, we fit a penalised ridge regression using a few \n",
    "\n",
    "## Packages\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# import preprocessing from sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "befd6736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Projects/Fraud/PCode\n"
     ]
    }
   ],
   "source": [
    "## Directories and paths\n",
    "\n",
    "# Set directories\n",
    "print(os.getcwd())\n",
    "dirRawData = \"../input/\"\n",
    "dirPData   = \"../PData/\"\n",
    "dirPOutput = \"../POutput/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad76fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "\n",
    "f_name = dirPData + '01_df_250k.pickle'\n",
    "\n",
    "with (open(f_name, \"rb\")) as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "df_train = dict_['df_train']\n",
    "df_test  = dict_['df_test']\n",
    "\n",
    "del f_name, dict_\n",
    "\n",
    "f_name = dirPData + '01_vars.pickle'\n",
    "\n",
    "with open(f_name, \"rb\") as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "vars_ind_numeric     = dict_['vars_ind_numeric']\n",
    "vars_ind_hccv        = dict_['vars_ind_hccv']\n",
    "vars_ind_categorical = dict_['vars_ind_categorical']\n",
    "vars_notToUse        = dict_['vars_notToUse']\n",
    "var_dep              = dict_['var_dep']\n",
    "\n",
    "del f_name, dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cba23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c2e42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y variable for train set\n",
    "y_train=df_train[var_dep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f178df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting categorical and numeric features to use and storing variable name in corresponding lists \n",
    "vars_ind_use=['f27','f29', 'e04','e02','b04']\n",
    "vars_ind_cat_use=['f27','f29','b04']\n",
    "vars_ind_numeric_use=['e02','e04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e1b071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting variables we want from train set\n",
    "df_train_use=df_train[vars_ind_use]\n",
    "\n",
    "# selecting variables we want from test set\n",
    "df_test_use=df_test[vars_ind_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b878ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-hot categorical variables for the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68a77b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f27\n",
      "f29\n",
      "b04\n"
     ]
    }
   ],
   "source": [
    "# loop to onehot all categorical variables we want to use for training\n",
    "# since categorical variables aren't automatically one-hotted in sklearn we do this manually\n",
    "\n",
    "vars_ind_onehot = []\n",
    "\n",
    "df_all_onehot_train = df_train_use.copy()\n",
    "\n",
    "for col in vars_ind_cat_use:\n",
    "    print(col)\n",
    "    \n",
    "    # use pd.get_dummies \n",
    "    df_oh = pd.get_dummies(df_train[col], drop_first=False)\n",
    "    \n",
    "    # Find the column name of the most frequent category\n",
    "    col_mostFreq = df_oh.sum(axis = 0).idxmax()\n",
    "    \n",
    "    # Drop the column of the most frequent category\n",
    "    df_oh = df_oh.drop(col_mostFreq, axis=1)\n",
    "        \n",
    "    # Rename the columns to have the original variable name as a prefix\n",
    "    oh_names = col + '_' + df_oh.columns.astype(str)\n",
    "    df_oh.columns = oh_names\n",
    "    \n",
    "    df_all_onehot_train = pd.concat([df_all_onehot_train, df_oh], axis = 1, sort = False)\n",
    "\n",
    "    del df_all_onehot_train[col]\n",
    "    vars_ind_onehot.extend(oh_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ba05394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f27\n",
      "f29\n",
      "b04\n"
     ]
    }
   ],
   "source": [
    "## One-hot categorical variables for the test set\n",
    "\n",
    "# loop to onehot all categorical variables we want to use for test set\n",
    "# since categorical variables aren't automatically one-hotted in sklearn we do this manually\n",
    "\n",
    "vars_ind_onehot_test = []\n",
    "df_all_onehot_test = df_test_use.copy()\n",
    "\n",
    "for col in vars_ind_cat_use:\n",
    "    print(col)\n",
    "    \n",
    "    # use pd.get_dummies on  df_all[col] \n",
    "    df_oh = pd.get_dummies(df_test[col], drop_first=False)\n",
    "    \n",
    "    # Find the column name of the most frequent category\n",
    "    col_mostFreq = df_oh.sum(axis = 0).idxmax()\n",
    "    \n",
    "    # Drop the column of the most frequent category\n",
    "    df_oh = df_oh.drop(col_mostFreq, axis=1)\n",
    "        \n",
    "    # Rename the columns to have the original variable name as a prefix\n",
    "    oh_names = col + '_' + df_oh.columns.astype(str)\n",
    "    df_oh.columns = oh_names\n",
    "    \n",
    "    df_all_onehot_test = pd.concat([df_all_onehot_test, df_oh], axis = 1, sort = False)\n",
    "\n",
    "    del df_all_onehot_test[col]\n",
    "    vars_ind_onehot_test.extend(oh_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7fe52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f552af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding splines to the numeric variables we randomly chose\n",
    "# some numeric variables may have non-linear effects so we spline them\n",
    "vars_ind_tospline = df_train_use[vars_ind_numeric_use].columns.tolist()\n",
    "\n",
    "# set variables to spline with unique values greater than 0 and because we want to spline all numeric variables\n",
    "vars_ind_tospline = df_train_use[vars_ind_numeric_use].columns[(df_train_use[vars_ind_numeric_use].nunique() > 0)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbbb97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the spline function\n",
    "def fn_tosplines(x):\n",
    "    # removing zeros to avoid issues where lots of values are zero\n",
    "    x_nonzero = x[x != 0]\n",
    "    ptiles = np.percentile(x_nonzero, [10, 20, 40, 60, 80, 90]) # choosing the percentile split\n",
    "    ptiles = np.unique(ptiles)\n",
    "    print(var, ptiles)\n",
    "    df_ptiles = pd.DataFrame({var: x}) # converting it to a dataframe\n",
    "    for idx, ptile in enumerate(ptiles):\n",
    "        df_ptiles[var + '_' + str(idx)] = np.maximum(0, x - ptiles[idx])\n",
    "    return(df_ptiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25473bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e02 [11. 20. 41. 60. 80. 89.]\n",
      "e04 [12. 18. 39. 60. 81. 89.]\n"
     ]
    }
   ],
   "source": [
    "# applying the function on the selected variables and concatinating it on the training set\n",
    "for var in vars_ind_tospline:\n",
    "    df_ptiles = fn_tosplines(df_train[var])\n",
    "    df_all_onehot_train.drop(columns=[var], inplace=True)\n",
    "    vars_ind_numeric_use.remove(var)\n",
    "    df_all_onehot_train = pd.concat([df_all_onehot_train, df_ptiles], axis=1, sort=False)\n",
    "    vars_ind_numeric_use.extend(df_ptiles.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46aafbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e02 [13. 23. 41. 60. 81. 90.]\n",
      "e04 [ 7. 18. 34. 54. 76. 87.]\n"
     ]
    }
   ],
   "source": [
    "# applying the function on the selected variables and concatinating it on the test set\n",
    "for var in vars_ind_tospline:\n",
    "    df_ptiles = fn_tosplines(df_test[var])\n",
    "    df_all_onehot_test.drop(columns=[var], inplace=True)\n",
    "    vars_ind_numeric_use.remove(var)\n",
    "    df_all_onehot_test = pd.concat([df_all_onehot_test, df_ptiles], axis=1, sort=False)\n",
    "    vars_ind_numeric_use.extend(df_ptiles.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfb52231",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Updating Independent Variables after OneHot and splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ab8b558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f27_A',\n",
       " 'f27_B',\n",
       " 'f27_C',\n",
       " 'f27_D',\n",
       " 'f27_E',\n",
       " 'f27_X',\n",
       " 'f29_A',\n",
       " 'f29_B',\n",
       " 'f29_C',\n",
       " 'f29_D',\n",
       " 'f29_F',\n",
       " 'f29_G',\n",
       " 'b04_B',\n",
       " 'b04_C',\n",
       " 'b04_D',\n",
       " 'b04_E',\n",
       " 'b04_F',\n",
       " 'b04_G',\n",
       " 'b04_H',\n",
       " 'b04_I',\n",
       " 'e02',\n",
       " 'e02_0',\n",
       " 'e02_1',\n",
       " 'e02_2',\n",
       " 'e02_3',\n",
       " 'e02_4',\n",
       " 'e02_5',\n",
       " 'e04',\n",
       " 'e04_0',\n",
       " 'e04_1',\n",
       " 'e04_2',\n",
       " 'e04_3',\n",
       " 'e04_4',\n",
       " 'e04_5']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_ind = df_all_onehot_train.columns.to_list()\n",
    "vars_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21006d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f27_A</th>\n",
       "      <th>f27_B</th>\n",
       "      <th>f27_C</th>\n",
       "      <th>f27_D</th>\n",
       "      <th>f27_E</th>\n",
       "      <th>f27_X</th>\n",
       "      <th>f29_B</th>\n",
       "      <th>f29_C</th>\n",
       "      <th>f29_D</th>\n",
       "      <th>f29_F</th>\n",
       "      <th>...</th>\n",
       "      <th>e02_3</th>\n",
       "      <th>e02_4</th>\n",
       "      <th>e02_5</th>\n",
       "      <th>e04</th>\n",
       "      <th>e04_0</th>\n",
       "      <th>e04_1</th>\n",
       "      <th>e04_2</th>\n",
       "      <th>e04_3</th>\n",
       "      <th>e04_4</th>\n",
       "      <th>e04_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>65</td>\n",
       "      <td>53.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>65</td>\n",
       "      <td>53.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248905 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f27_A  f27_B  f27_C  f27_D  f27_E  f27_X  f29_B  f29_C  f29_D  f29_F  \\\n",
       "0           1      0      0      0      0      0      0      0      0      0   \n",
       "1           0      0      0      0      0      0      0      0      1      0   \n",
       "2           0      0      0      0      0      0      0      0      1      0   \n",
       "3           1      0      0      0      0      0      0      0      0      0   \n",
       "4           0      0      0      0      0      0      0      0      1      0   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "249995      0      0      0      0      0      0      0      0      1      0   \n",
       "249996      1      0      0      0      0      0      0      0      0      0   \n",
       "249997      0      0      0      0      0      0      0      0      1      0   \n",
       "249998      0      0      0      0      0      0      0      0      1      0   \n",
       "249999      0      0      0      0      0      0      0      0      1      0   \n",
       "\n",
       "        ...  e02_3  e02_4  e02_5  e04  e04_0  e04_1  e04_2  e04_3  e04_4  \\\n",
       "0       ...    0.0    0.0    0.0   44   32.0   26.0    5.0    0.0    0.0   \n",
       "1       ...    0.0    0.0    0.0   44   32.0   26.0    5.0    0.0    0.0   \n",
       "2       ...    0.0    0.0    0.0   44   32.0   26.0    5.0    0.0    0.0   \n",
       "3       ...   34.0   14.0    5.0   65   53.0   47.0   26.0    5.0    0.0   \n",
       "4       ...   34.0   14.0    5.0   65   53.0   47.0   26.0    5.0    0.0   \n",
       "...     ...    ...    ...    ...  ...    ...    ...    ...    ...    ...   \n",
       "249995  ...   10.0    0.0    0.0   12    0.0    0.0    0.0    0.0    0.0   \n",
       "249996  ...    0.0    0.0    0.0    3    0.0    0.0    0.0    0.0    0.0   \n",
       "249997  ...    0.0    0.0    0.0    3    0.0    0.0    0.0    0.0    0.0   \n",
       "249998  ...    0.0    0.0    0.0    3    0.0    0.0    0.0    0.0    0.0   \n",
       "249999  ...    0.0    0.0    0.0    3    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "        e04_5  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "...       ...  \n",
       "249995    0.0  \n",
       "249996    0.0  \n",
       "249997    0.0  \n",
       "249998    0.0  \n",
       "249999    0.0  \n",
       "\n",
       "[248905 rows x 33 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ridge regression without setting the optimal lambda\n",
    "\n",
    "# Column 'f29_A' was removed because it did not appear in the onehot encoding of the test set\n",
    "df_all_onehot_train=df_all_onehot_train.drop('f29_A',axis=1)\n",
    "\n",
    "# Defining the dependent and independent variables\n",
    "X_train = df_all_onehot_train\n",
    "y_train = y_train\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f78ebbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 8.92 s, total: 19.3 s\n",
      "Wall time: 6.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=10, normalize=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fitting the model using 10-fold Cross-Validation with default parameters \n",
    "# To see performance of basic model\n",
    "\n",
    "ridgeCV_ = RidgeCV(fit_intercept=True\n",
    "                   ,normalize=True # normalising the data\n",
    "                   ,cv=10)\n",
    "\n",
    "ridgeCV_.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31fa78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeCV_.coef_ # model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeCV_.predict(df_all_onehot_train) # model train predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model \n",
    "\n",
    "ridgeCV_.intercept_ # model intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7cc386",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ridge regression\n",
    "\n",
    "#We fit a grid for different values of lambda ranging from 0-1 at a step of 0.01.  For each penalised model we fit, we will calculate and store the Mean Absolute (prediction) Error on the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e32b9ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal lambda using grid\n",
    "\n",
    "# import libraries and modules for grid and repeatedKfold\n",
    "from numpy import arange\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14307565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -0.493\n",
      "Config: {'alpha': 0.43}\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid\n",
    "grid = dict()\n",
    "grid['alpha'] = arange(0, 1, 0.01)\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search.fit(X=X_train, y=y_train)\n",
    "# summarize\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.best_score_ # best mae found is 0.493 with and an alpha of 0.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9cef325",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=results.predict(df_all_onehot_test) #use model to predict results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4acf1ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.028127490578694236"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.min() # some predictions negative due to nature of linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b4cb010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7558342527076346"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we clip predictions so that they are betweeen 0 and 1 as they respresent probabilities\n",
    "clipped = np.clip(predictions, 0, 1)\n",
    "clipped.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "907c87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_ridge= pd.DataFrame() # create empty df\n",
    "\n",
    "df_sub_ridge['unique_id']=df_test[\"unique_id\"] # add unique id from test set\n",
    "\n",
    "df_sub_ridge['Predicted']=pd.DataFrame(clipped) # add predictions \n",
    "\n",
    "df_sub_ridge.to_csv('../POutput/df_sub_ridge1.csv', index=False) # covert df to csv for kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e11a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
